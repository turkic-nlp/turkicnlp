<p align="center">
  <img src="images/cover.png" alt="TurkicNLP â€” Language Family Tree" width="300">
</p>

<h1 align="center">TurkicNLP</h1>

<p align="center">
  <strong>NLP toolkit for 20+ Turkic languages</strong> â€” a pip-installable Python library inspired by <a href="https://stanfordnlp.github.io/stanza/">Stanza</a>, with adaptations for the low-resource, morphologically rich Turkic language family.
</p>

<p align="center">
  Developed by <a href="https://sherzod-hakimov.github.io/">Sherzod Hakimov</a>
</p>

<p align="center">
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-Apache%202.0-blue.svg" alt="License: Apache-2.0"></a>
  <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.9+-blue.svg" alt="Python 3.9+"></a>
  <img src="https://img.shields.io/badge/status-pre--alpha-orange.svg" alt="Status: Pre-Alpha">
  <img src="https://img.shields.io/badge/languages-24_Turkic-green.svg" alt="24 Turkic Languages">
</p>

## Features

- **24 Turkic languages** from Turkish to Sakha, Kazakh to Uyghur
- **Script-aware from the ground up** â€” Latin, Cyrillic, Perso-Arabic, Old Turkic Runic
- **Automatic script detection** and bidirectional transliteration
- **Apertium FST morphology** for ~20 languages via Python-native `hfst` bindings (no system install)
- **Neural processors** â€” POS tagging, dependency parsing, NER, sentiment analysis
- **License isolation** â€” library is Apache-2.0; Apertium GPL-3.0 data downloaded separately
- **Stanza-compatible API** â€” `Pipeline`, `Document`, `Sentence`, `Word`

## Installation

```bash
pip install turkicnlp
```

With optional dependencies:

```bash
pip install turkicnlp[hfst]          # Apertium FST support
pip install turkicnlp[torch]         # Neural model support
pip install turkicnlp[all]           # Everything
pip install turkicnlp[dev]           # Development tools
```

## Quick Start

```python
import turkicnlp

# Download models for a language
turkicnlp.download("kaz")

# Build a pipeline
nlp = turkicnlp.Pipeline("kaz", processors=["tokenize", "pos", "lemma", "depparse"])

# Process text
doc = nlp("ĞœĞµĞ½ Ğ¼ĞµĞºÑ‚ĞµĞ¿ĞºĞµ Ğ±Ğ°Ñ€Ğ´Ñ‹Ğ¼")

# Access annotations
for sentence in doc.sentences:
    for word in sentence.words:
        print(f"{word.text}\t{word.lemma}\t{word.upos}\t{word.feats}")

# Export to CoNLL-U
print(doc.to_conllu())
```

### Multi-Script Support

```python
# Kazakh â€” auto-detects Cyrillic vs Latin
doc = nlp("ĞœĞµĞ½ Ğ¼ĞµĞºÑ‚ĞµĞ¿ĞºĞµ Ğ±Ğ°Ñ€Ğ´Ñ‹Ğ¼")    # Cyrillic
doc = nlp("Men mektepke bardym")     # Latin

# Explicit script selection
nlp_cyrl = turkicnlp.Pipeline("kaz", script="Cyrl")
nlp_latn = turkicnlp.Pipeline("kaz", script="Latn")

# Transliteration bridge â€” run Cyrillic model on Latin input
nlp = turkicnlp.Pipeline("kaz", script="Latn", transliterate_to="Cyrl")
```

### Uyghur (Perso-Arabic)

```python
nlp_ug = turkicnlp.Pipeline("uig", script="Arab")
doc = nlp_ug("Ù…Û•Ù† Ù…Û•ÙƒØªÛ•Ù¾ÙƒÛ• Ø¨Ø§Ø±Ø¯Ù‰Ù…")
```

## Supported Languages and Components

<p align="center">
  <img src="images/Turkic_Languages_distribution_map.png" alt="Distribution map of Turkic languages" width="700">
  <br>
  <em>Geographic distribution of Turkic languages (source: <a href="https://commons.wikimedia.org/wiki/File:Turkic_Languages_distribution_map.png">Wikimedia Commons</a>)</em>
</p>

The table below shows all supported languages with their available scripts and processor status. Components marked with the Apertium FST backend are available via GPL-3.0 licensed data downloaded separately.

**Legend:** âœ… = Implemented | ğŸ”§ = Planned | â€” = Not applicable

### Oghuz Branch

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Turkish](https://en.wikipedia.org/wiki/Turkish_language) | `tur` | Latn | âœ… rule, ğŸ”§ neural | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural |
| [Azerbaijani](https://en.wikipedia.org/wiki/Azerbaijani_language) | `aze` | Latn, Cyrl | âœ… rule | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | â€” |
| [Iranian Azerbaijani](https://en.wikipedia.org/wiki/South_Azerbaijani_language) | `azb` | Arab | ğŸ”§ rule_arabic | â€” | â€” | â€” | â€” | â€” | â€” |
| [Turkmen](https://en.wikipedia.org/wiki/Turkmen_language) | `tuk` | Latn | âœ… rule | âœ… Apertium (beta) | ğŸ”§ neural | ğŸ”§ neural | â€” | â€” | â€” |
| [Gagauz](https://en.wikipedia.org/wiki/Gagauz_language) | `gag` | Latn | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |

### Kipchak Branch

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Kazakh](https://en.wikipedia.org/wiki/Kazakh_language) | `kaz` | Cyrl, Latn | âœ… rule, ğŸ”§ neural | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural |
| [Kyrgyz](https://en.wikipedia.org/wiki/Kyrgyz_language) | `kir` | Cyrl | âœ… rule | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | â€” | â€” | â€” |
| [Tatar](https://en.wikipedia.org/wiki/Tatar_language) | `tat` | Cyrl, Latn | âœ… rule | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | â€” | â€” | â€” |
| [Bashkir](https://en.wikipedia.org/wiki/Bashkir_language) | `bak` | Cyrl | âœ… rule | âœ… Apertium (beta) | â€” | â€” | â€” | â€” | â€” |
| [Crimean Tatar](https://en.wikipedia.org/wiki/Crimean_Tatar_language) | `crh` | Latn, Cyrl | âœ… rule | âœ… Apertium (beta) | â€” | â€” | â€” | â€” | â€” |
| [Karakalpak](https://en.wikipedia.org/wiki/Karakalpak_language) | `kaa` | Latn, Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Nogai](https://en.wikipedia.org/wiki/Nogai_language) | `nog` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Kumyk](https://en.wikipedia.org/wiki/Kumyk_language) | `kum` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Karachay-Balkar](https://en.wikipedia.org/wiki/Karachay-Balkar_language) | `krc` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |

### Karluk Branch

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Uzbek](https://en.wikipedia.org/wiki/Uzbek_language) | `uzb` | Latn, Cyrl | âœ… rule | âœ… Apertium | ğŸ”§ neural | ğŸ”§ neural | ğŸ”§ neural | â€” | â€” |
| [Uyghur](https://en.wikipedia.org/wiki/Uyghur_language) | `uig` | Arab, Latn | ğŸ”§ rule_arabic, âœ… rule (Latn) | âœ… Apertium (beta) | â€” | â€” | â€” | â€” | â€” |

### Siberian Branch

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Sakha (Yakut)](https://en.wikipedia.org/wiki/Sakha_language) | `sah` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Altai](https://en.wikipedia.org/wiki/Altai_language) | `alt` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Tuvan](https://en.wikipedia.org/wiki/Tuvan_language) | `tyv` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |
| [Khakas](https://en.wikipedia.org/wiki/Khakas_language) | `kjh` | Cyrl | âœ… rule | âœ… Apertium (proto) | â€” | â€” | â€” | â€” | â€” |

### Oghur Branch

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Chuvash](https://en.wikipedia.org/wiki/Chuvash_language) | `chv` | Cyrl | âœ… rule | âœ… Apertium (beta) | â€” | â€” | â€” | â€” | â€” |

### Historical Languages

| Language | Code | Script(s) | Tokenize | Morph (FST) | POS | Lemma | DepParse | NER | Sentiment |
|---|---|---|---|---|---|---|---|---|---|
| [Ottoman Turkish](https://en.wikipedia.org/wiki/Ottoman_Turkish_language) | `ota` | Arab, Latn | ğŸ”§ rule_arabic | â€” | â€” | â€” | â€” | â€” | â€” |
| [Old Turkish](https://en.wikipedia.org/wiki/Old_Turkic_language) | `otk` | Orkh, Latn | ğŸ”§ rule | â€” | â€” | â€” | â€” | â€” | â€” |

### Transliteration Support

| Language Pair | Direction | Status |
|---|---|---|
| Kazakh Cyrillic â†” Latin | Bidirectional | âœ… |
| Uzbek Cyrillic â†’ Latin | One-way | âœ… |
| Uyghur Arabic â†’ Latin (ULY) | One-way | âœ… |
| Crimean Tatar Cyrillic â†’ Latin | One-way | âœ… |
| Azerbaijani Cyrillic â†” Latin | Bidirectional | ğŸ”§ |
| Tatar Cyrillic â†” Latin | Bidirectional | ğŸ”§ |

### Apertium FST Quality Levels

| Level | Description | Languages |
|---|---|---|
| **Production** | >90% coverage on news text | Turkish, Kazakh, Tatar |
| **Stable** | Good coverage, actively maintained | Azerbaijani, Kyrgyz, Uzbek |
| **Beta** | Reasonable coverage, some gaps | Turkmen, Bashkir, Uyghur, Crimean Tatar, Chuvash |
| **Prototype** | Limited coverage, experimental | Gagauz, Sakha, Karakalpak, Nogai, Kumyk, Karachay-Balkar, Altai, Tuvan, Khakas |

### Model Catalog and Apertium Downloads

TurkicNLP uses a model catalog to define download sources per language/script/processor. The catalog lives in:

- `turkicnlp/resources/catalog.json` (packaged default)
- Remote override: `ModelRegistry.CATALOG_URL` (or `TURKICNLP_CATALOG_URL`)

For each language, the catalog stores the Apertium source repo and the expected FST script. When `turkicnlp.download()` is called, it reads the catalog and downloads precompiled `.hfst` binaries from the `url` fields. If a language has no URL configured, download will fail with a clear error until the catalog is populated with hosted binaries (for example, a `turkic-nlp/apertium-data` releases repository).

## Architecture

TurkicNLP follows Stanza's modular pipeline design:

```
Pipeline("tur", processors=["tokenize", "morph", "pos", "depparse"])
    â”‚
    â–¼
  Document â”€â”€â”€ text: "Ben okula vardÄ±m"
    â”‚
    â”œâ”€â”€ script_detect    â†’ script = "Latn"
    â”œâ”€â”€ tokenize         â†’ sentences, tokens, words
    â”œâ”€â”€ morph (Apertium) â†’ lemma, pos, feats (via HFST)
    â”œâ”€â”€ pos (neural)     â†’ refined UPOS, XPOS, feats
    â””â”€â”€ depparse         â†’ head, deprel
    â”‚
    â–¼
  Document â”€â”€â”€ annotated with all layers
```


```
Pipeline("kaz", processors=["tokenize", "morph", "pos", "depparse"])
    â”‚
    â–¼
  Document â”€â”€â”€ text: "ĞœĞµĞ½ Ğ¼ĞµĞºÑ‚ĞµĞ¿ĞºĞµ Ğ±Ğ°Ñ€Ğ´Ñ‹Ğ¼"
    â”‚
    â”œâ”€â”€ script_detect    â†’ script = "Cyrl"
    â”œâ”€â”€ tokenize         â†’ sentences, tokens, words
    â”œâ”€â”€ morph (Apertium) â†’ lemma, pos, feats (via HFST)
    â”œâ”€â”€ pos (neural)     â†’ refined UPOS, XPOS, feats
    â””â”€â”€ depparse         â†’ head, deprel
    â”‚
    â–¼
  Document â”€â”€â”€ annotated with all layers
```

### Key Abstractions

- **Document** â†’ Sentence â†’ Token â†’ Word hierarchy (maps to CoNLL-U)
- **Processor** ABC with `PROVIDES`, `REQUIRES`, `NAME` class attributes
- **Pipeline** orchestrator with dependency resolution and script-aware model loading
- **ProcessorRegistry** for pluggable backends (Apertium, neural, rule-based)
- **ModelRegistry** with remote catalog and local caching at `~/.turkicnlp/models/`

### Model Storage Layout

```
~/.turkicnlp/models/
â”œâ”€â”€ kaz/
â”‚   â”œâ”€â”€ Cyrl/
â”‚   â”‚   â”œâ”€â”€ tokenize/rule/
â”‚   â”‚   â”œâ”€â”€ morph/apertium/    â† GPL-3.0 (downloaded separately)
â”‚   â”‚   â”‚   â”œâ”€â”€ kaz.automorf.hfst
â”‚   â”‚   â”‚   â”œâ”€â”€ LICENSE
â”‚   â”‚   â”‚   â””â”€â”€ metadata.json
â”‚   â”‚   â”œâ”€â”€ pos/neural/
â”‚   â”‚   â””â”€â”€ depparse/neural/
â”‚   â””â”€â”€ Latn/
â”‚       â””â”€â”€ tokenize/rule/
â”œâ”€â”€ tur/
â”‚   â””â”€â”€ Latn/
â”‚       â””â”€â”€ ...
â””â”€â”€ catalog.json
```

## License

- **Library code**: [Apache License 2.0](LICENSE)
- **Apertium FST data**: [GPL-3.0](https://www.gnu.org/licenses/gpl-3.0.html) â€” downloaded separately at runtime, never bundled in the pip package

## Development

```bash
git clone https://github.com/turkic-nlp/turkicnlp.git
cd turkicnlp
pip install -e ".[dev]"
pytest
```

## Contributing

Contributions are welcome, especially:

- **New language support** â€” tag mappings, abbreviation lists, test data
- **Neural model training** â€” POS taggers, parsers, NER models
- **Apertium FST improvements** â€” better coverage for prototype-level languages
- **Other** -  any other aspect that you want

## Citation

If you use TurkicNLP in your research, please cite:

```bibtex
@software{turkicnlp,
  title = {TurkicNLP: NLP Toolkit for Turkic Languages},
  author = {Sherzod Hakimov},
  year = {2026},
  url = {https://github.com/turkic-nlp/turkicnlp},
  license = {Apache-2.0},
}
```

## Acknowledgements

- [Stanza](https://stanfordnlp.github.io/stanza/) â€” for the architectural inspiration
- [Apertium](https://apertium.org/) â€” for morphological transducers covering 20 Turkic languages
- [SIGTURK](https://sigturk.com/) â€” ACL Special Interest Group on Turkic Languages
- [ISSAI](https://issai.nu.edu.kz/) â€” for Kazakh NLP resources
- [Universal Dependencies](https://universaldependencies.org/) â€” for Turkic treebanks
- [Turkic Interlingua](https://github.com/turkic-interlingua) - Resources for Machine Translation for Turkic Languages
